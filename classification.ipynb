{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqzuxLTaLZ5T",
        "colab_type": "code",
        "outputId": "dde0e809-6a4c-4be4-eb5d-17394681aaf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import helper\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:01, 14546121.62it/s]                              \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 104266.31it/s]           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:01, 4385157.40it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 35655.83it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC-WIb16WLAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl0A5WyBLjgu",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDJxc2cgLlBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn, optim\n",
        "\n",
        "model = nn.Sequential(nn.Linear(784,128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128,64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64,10),\n",
        "                      nn.LogSoftmax(dim=1)\n",
        "                     )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKx6gua8Luah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.003)\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t7fOLsLL6cr",
        "colab_type": "code",
        "outputId": "ff087691-cc56-4051-d605-97c432118c2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "epoch = 5\n",
        "\n",
        "for e in range(epoch):\n",
        "    for images, labels in trainloader:\n",
        "        running_loss = 0    \n",
        "        \n",
        "      \n",
        "        logits = model(images.view(images.shape[0],-1))\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "#         take the optimizer step\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss +=loss.item()\n",
        "        \n",
        "    else:\n",
        "        print(f'training loss:{running_loss/len(trainloader)}')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training loss:0.0007925426909155938\n",
            "training loss:0.0007302328975978436\n",
            "training loss:0.0004747764133949524\n",
            "training loss:0.0010747891753467161\n",
            "training loss:0.0005662169283641173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC09igiwM-Qu",
        "colab_type": "code",
        "outputId": "1274e8f3-2d0c-4f95-8500-1fe1ab2d894c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(trainloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "938"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agRLF7PDNFK4",
        "colab_type": "code",
        "outputId": "fe938575-03a7-40c9-8ae3-fa56fc87e2c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "running_loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bla2f3INHGR",
        "colab_type": "code",
        "outputId": "b0e71634-2f9a-4bf2-8b14-9abb65cebd04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "criterion = nn.NLLLoss()\n",
        "loss = criterion(logits,labels)\n",
        "loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(nan, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73G2MN8iNxmb",
        "colab_type": "code",
        "outputId": "9759f634-f537-4350-f55a-8d4f42fbcbcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "a = torch.randn(1,3)>5\n",
        "b = torch.randn(1,3)>5\n",
        "\n",
        "loss = criterion(a,b)\n",
        "loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-ee045a3c6b94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1869\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1871\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1872\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: _thnn_nll_loss_forward not supported on CPUType for Byte"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUdfwK1hPdJu",
        "colab_type": "code",
        "outputId": "3800ed76-ad2a-41d4-db88-7a4cdcea48af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "logits = model(images.view(images.shape[0],-1))\n",
        "logits"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.1720, -2.2152, -2.4373, -2.3061, -2.4246, -2.4374, -2.3280, -2.1656,\n",
              "         -2.2447, -2.3452],\n",
              "        [-2.1901, -2.1988, -2.4390, -2.2851, -2.4370, -2.4414, -2.3578, -2.0959,\n",
              "         -2.2915, -2.3539],\n",
              "        [-2.1866, -2.2627, -2.3694, -2.3125, -2.3839, -2.4863, -2.3167, -2.1775,\n",
              "         -2.2739, -2.2942],\n",
              "        [-2.1001, -2.3003, -2.5012, -2.3467, -2.3649, -2.3441, -2.3078, -2.1688,\n",
              "         -2.2809, -2.3669],\n",
              "        [-2.2056, -2.2646, -2.4057, -2.3417, -2.3870, -2.4938, -2.2694, -2.1424,\n",
              "         -2.2068, -2.3616],\n",
              "        [-2.1989, -2.2906, -2.4139, -2.1907, -2.3653, -2.4904, -2.2800, -2.1961,\n",
              "         -2.2586, -2.3887],\n",
              "        [-2.1301, -2.2595, -2.4738, -2.3038, -2.4140, -2.3772, -2.2946, -2.1442,\n",
              "         -2.2992, -2.3854],\n",
              "        [-2.1419, -2.3012, -2.4915, -2.2761, -2.3956, -2.4378, -2.3096, -2.1534,\n",
              "         -2.2673, -2.3075],\n",
              "        [-2.1763, -2.2422, -2.4621, -2.2995, -2.4069, -2.4952, -2.3180, -2.1127,\n",
              "         -2.2913, -2.2861],\n",
              "        [-2.1347, -2.2934, -2.3795, -2.3089, -2.4197, -2.5478, -2.4077, -2.1031,\n",
              "         -2.2643, -2.2478],\n",
              "        [-2.1947, -2.2561, -2.4748, -2.2879, -2.3797, -2.5006, -2.3091, -2.1297,\n",
              "         -2.2554, -2.2975],\n",
              "        [-2.1255, -2.2456, -2.4422, -2.3435, -2.3742, -2.5178, -2.4277, -2.1253,\n",
              "         -2.2876, -2.2170],\n",
              "        [-2.1690, -2.3178, -2.4246, -2.2769, -2.3659, -2.5000, -2.3191, -2.1511,\n",
              "         -2.2157, -2.3396],\n",
              "        [-2.1740, -2.3032, -2.4108, -2.2765, -2.3758, -2.4854, -2.3713, -2.1618,\n",
              "         -2.2517, -2.2630],\n",
              "        [-2.1490, -2.2515, -2.3990, -2.3236, -2.3896, -2.4851, -2.3686, -2.1722,\n",
              "         -2.2370, -2.3013],\n",
              "        [-2.1728, -2.2671, -2.3596, -2.3591, -2.4007, -2.5062, -2.3521, -2.1167,\n",
              "         -2.2229, -2.3285],\n",
              "        [-2.1892, -2.2723, -2.3987, -2.3074, -2.3482, -2.4623, -2.3218, -2.2123,\n",
              "         -2.2670, -2.2768],\n",
              "        [-2.1557, -2.2609, -2.4129, -2.2840, -2.3975, -2.4927, -2.3871, -2.1320,\n",
              "         -2.2767, -2.2851],\n",
              "        [-2.1587, -2.1884, -2.4796, -2.3515, -2.4180, -2.4655, -2.3170, -2.1578,\n",
              "         -2.2413, -2.3138],\n",
              "        [-2.1602, -2.2325, -2.4141, -2.2957, -2.4004, -2.4773, -2.3541, -2.1331,\n",
              "         -2.3071, -2.3060],\n",
              "        [-2.1943, -2.3084, -2.3455, -2.2783, -2.3676, -2.5109, -2.3050, -2.1375,\n",
              "         -2.2636, -2.3612],\n",
              "        [-2.0945, -2.2024, -2.4099, -2.3232, -2.3917, -2.4969, -2.2817, -2.2149,\n",
              "         -2.2648, -2.4124],\n",
              "        [-2.1060, -2.2697, -2.4846, -2.3160, -2.4241, -2.4456, -2.3073, -2.1926,\n",
              "         -2.2165, -2.3276],\n",
              "        [-2.1791, -2.3203, -2.3550, -2.2587, -2.3791, -2.4341, -2.3632, -2.1617,\n",
              "         -2.2399, -2.3730],\n",
              "        [-2.1124, -2.2792, -2.4947, -2.2811, -2.3958, -2.4750, -2.3104, -2.1471,\n",
              "         -2.2719, -2.3272],\n",
              "        [-2.2111, -2.2825, -2.4089, -2.2784, -2.3784, -2.4500, -2.3595, -2.1465,\n",
              "         -2.2525, -2.2972],\n",
              "        [-2.1368, -2.2177, -2.4174, -2.3560, -2.3927, -2.4407, -2.4336, -2.1576,\n",
              "         -2.2870, -2.2464],\n",
              "        [-2.1557, -2.4038, -2.4021, -2.2694, -2.3574, -2.4948, -2.3462, -2.1090,\n",
              "         -2.2021, -2.3532],\n",
              "        [-2.0842, -2.3184, -2.4456, -2.3550, -2.4199, -2.5037, -2.3625, -2.1573,\n",
              "         -2.1976, -2.2635],\n",
              "        [-2.1693, -2.2368, -2.4608, -2.3151, -2.3654, -2.4709, -2.3313, -2.1805,\n",
              "         -2.2456, -2.2987],\n",
              "        [-2.1538, -2.2900, -2.4467, -2.3119, -2.4081, -2.5016, -2.3588, -2.1177,\n",
              "         -2.2069, -2.3005],\n",
              "        [-2.2245, -2.3637, -2.4329, -2.2936, -2.3390, -2.4230, -2.3616, -2.0961,\n",
              "         -2.2587, -2.2793],\n",
              "        [-2.2106, -2.2834, -2.4012, -2.2139, -2.3775, -2.4754, -2.3248, -2.1772,\n",
              "         -2.2386, -2.3659],\n",
              "        [-2.1298, -2.2640, -2.4848, -2.2804, -2.4053, -2.4054, -2.3155, -2.1964,\n",
              "         -2.2879, -2.3050],\n",
              "        [-2.1539, -2.2715, -2.4667, -2.2847, -2.3808, -2.4327, -2.2892, -2.1682,\n",
              "         -2.2927, -2.3315],\n",
              "        [-2.1339, -2.2924, -2.3802, -2.3127, -2.3729, -2.4387, -2.4081, -2.2243,\n",
              "         -2.2178, -2.2865],\n",
              "        [-2.1669, -2.2733, -2.4187, -2.3064, -2.3879, -2.4784, -2.3765, -2.1169,\n",
              "         -2.2776, -2.2797],\n",
              "        [-2.1789, -2.2882, -2.4102, -2.2907, -2.3859, -2.4533, -2.3548, -2.1592,\n",
              "         -2.2376, -2.3092],\n",
              "        [-2.1992, -2.3633, -2.4310, -2.2545, -2.3428, -2.4517, -2.3254, -2.1156,\n",
              "         -2.2445, -2.3472],\n",
              "        [-2.1006, -2.2672, -2.4537, -2.2933, -2.4068, -2.5114, -2.3260, -2.1146,\n",
              "         -2.2812, -2.3505],\n",
              "        [-2.1902, -2.2890, -2.3582, -2.3257, -2.3690, -2.4479, -2.2533, -2.1338,\n",
              "         -2.2923, -2.4088],\n",
              "        [-2.1586, -2.2889, -2.4571, -2.3273, -2.3879, -2.4913, -2.3135, -2.1631,\n",
              "         -2.2104, -2.2854],\n",
              "        [-2.1850, -2.3030, -2.3451, -2.2623, -2.3949, -2.4873, -2.4253, -2.1313,\n",
              "         -2.2513, -2.2936],\n",
              "        [-2.1548, -2.2484, -2.4552, -2.3444, -2.4009, -2.5326, -2.3254, -2.1478,\n",
              "         -2.1962, -2.2931],\n",
              "        [-2.1669, -2.1770, -2.4292, -2.3170, -2.4194, -2.4555, -2.3246, -2.1647,\n",
              "         -2.2804, -2.3459],\n",
              "        [-2.1578, -2.2483, -2.4570, -2.3021, -2.4061, -2.4932, -2.3299, -2.1011,\n",
              "         -2.2937, -2.3047],\n",
              "        [-2.1820, -2.4079, -2.3952, -2.2691, -2.3859, -2.4295, -2.4015, -2.0745,\n",
              "         -2.2358, -2.3084],\n",
              "        [-2.2029, -2.3269, -2.3543, -2.2858, -2.3511, -2.4619, -2.2816, -2.0883,\n",
              "         -2.2610, -2.4714],\n",
              "        [-2.1958, -2.4421, -2.3715, -2.2240, -2.3389, -2.4371, -2.3173, -2.0980,\n",
              "         -2.2154, -2.4528],\n",
              "        [-2.1084, -2.1989, -2.4424, -2.3312, -2.4467, -2.3583, -2.2978, -2.1525,\n",
              "         -2.3200, -2.4372],\n",
              "        [-2.1680, -2.2998, -2.3665, -2.3033, -2.3616, -2.4728, -2.3234, -2.1904,\n",
              "         -2.2637, -2.3109],\n",
              "        [-2.1912, -2.2386, -2.3888, -2.2373, -2.3822, -2.4290, -2.2655, -2.1878,\n",
              "         -2.2906, -2.4592],\n",
              "        [-2.1668, -2.3026, -2.3513, -2.2908, -2.4100, -2.4655, -2.3213, -2.1697,\n",
              "         -2.2571, -2.3308],\n",
              "        [-2.1837, -2.3775, -2.4166, -2.3095, -2.3698, -2.5139, -2.3714, -2.0808,\n",
              "         -2.1935, -2.2837],\n",
              "        [-2.1756, -2.2673, -2.4390, -2.2947, -2.3850, -2.5307, -2.3566, -2.1279,\n",
              "         -2.2443, -2.2701],\n",
              "        [-2.1975, -2.2968, -2.3406, -2.3109, -2.3821, -2.4605, -2.3486, -2.1590,\n",
              "         -2.2165, -2.3516],\n",
              "        [-2.1454, -2.1852, -2.4103, -2.3128, -2.4340, -2.3803, -2.3176, -2.1634,\n",
              "         -2.3226, -2.4071],\n",
              "        [-2.1725, -2.2365, -2.4829, -2.3266, -2.4055, -2.4136, -2.2970, -2.1704,\n",
              "         -2.2829, -2.2852],\n",
              "        [-2.0907, -2.2580, -2.4401, -2.3143, -2.4300, -2.5470, -2.3482, -2.1442,\n",
              "         -2.2301, -2.3096],\n",
              "        [-2.1530, -2.2805, -2.4349, -2.2989, -2.3760, -2.3586, -2.2749, -2.1948,\n",
              "         -2.3155, -2.3721],\n",
              "        [-2.1660, -2.2920, -2.3611, -2.2954, -2.3868, -2.4817, -2.3281, -2.1801,\n",
              "         -2.2855, -2.2879],\n",
              "        [-2.1444, -2.2900, -2.4443, -2.2890, -2.4042, -2.4773, -2.3888, -2.1375,\n",
              "         -2.2775, -2.2358],\n",
              "        [-2.2051, -2.4106, -2.4433, -2.2597, -2.3161, -2.4355, -2.3439, -2.0981,\n",
              "         -2.2144, -2.3573],\n",
              "        [-2.1646, -2.3035, -2.3143, -2.3195, -2.3845, -2.4524, -2.3603, -2.1981,\n",
              "         -2.2873, -2.2733]], grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    }
  ]
}